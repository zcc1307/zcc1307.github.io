---
layout: page
title: Research
permalink: /research
---

## Research

My research is on interactive machine learning, where learning agents actively engage in data collection to make decisions or gain useful insights. Such interactive nature of learning
processes enables learning agents to focus on collecting data from the relevant parts of the environment, thus allowing to save data collection effort (which oftentimes translates to 
onerous human labor or experimental cost). My reserach goal is to understand and establish principled ways to design interactive machine learning algorithms with efficiency guarantees (e.g. sample efficiency, computational efficiency), and evaluate them experimentally in simulated and real-world datasets and environments. Here are some research topics I have been working on: 

### Imitation Learning

Imitation learning (IL), or Learning from Demonstrations, models the setting where a learning agent learns from a demonstrating expert to obtain intelligent sequential decision making behavior. Compared with reinforcement learning, imitation learning has the advantages that: (1) it gets around the reward misspecification problem and (2) it can mitigate the challenge 
of exploration. Such paradigm has been successfully deployed in e.g. robotics and autonomous driving. My research in imitation learning ([LZ22](https://arxiv.org/abs/2209.12868), [LZ24](https://arxiv.org/abs/2312.16860)) has been focused on understanding the power of interactive expert demonstrations: if we have an expert that can provide real-time, interactive action demonstration (cf. offline IL with expert demonstration trajectories readily available), how can we best utilize it to save its effort?


### Exploration in Bandits and Reinforcement Learning Settings

A wide range of sequential decision making problems require learning agents to perform exploration to learn about relevant parts of the environment. E.g., a robot needs to traverse a part of the maze before it finds way to its goal; a product recommendation system might want to gather information about a user's interest by trying to suggest users products they may 
like and see their reactions. My research in this area has been focused on understanding how to perform efficient exploration in structured environments, e.g., in the presence of large action spaces ([KLSZ20](https://arxiv.org/abs/1902.01520), [MZCKLS20](https://arxiv.org/abs/2006.06040)), multi-task setting (e.g. [WZSRC20](https://arxiv.org/abs/2010.15390)), and environments with sparsity and low-rankness properties ([JZJ22](https://arxiv.org/abs/2210.15345), [JZJ24](https://arxiv.org/abs/2402.11156)). 

### Active Learning


### Multi-task and Transfer Learning


### Interdisciplinary Collaboration
