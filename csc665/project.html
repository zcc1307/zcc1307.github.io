<!doctype html>
<html >
<head>

    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <!--[if lt IE 9]>
                <script src="http://css3-mediaqueries-js.googlecode.com/svn/trunk/css3-mediaqueries.js"></script>
        <![endif]-->
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />

  <link rel="stylesheet" type="text/css" href="/templates/pandoc-bootstrap-adaptive-template/tufte.css" />

   <link href="https://vjs.zencdn.net/5.4.4/video-js.css" rel="stylesheet" />



<script src="//ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script>
<script type='text/javascript' src='/templates/pandoc-bootstrap-adaptive-template/menu/js/jquery.cookie.js'></script>
<script type='text/javascript' src='/templates/pandoc-bootstrap-adaptive-template/menu/js/jquery.hoverIntent.minified.js'></script>
<script type='text/javascript' src='/templates/pandoc-bootstrap-adaptive-template/menu/js/jquery.dcjqaccordion.2.7.min.js'></script>

<link href="/templates/pandoc-bootstrap-adaptive-template/menu/css/skins/blue.css" rel="stylesheet" type="text/css" />
<link href="/templates/pandoc-bootstrap-adaptive-template/menu/css/skins/graphite.css" rel="stylesheet" type="text/css" />
<link href="/templates/pandoc-bootstrap-adaptive-template/menu/css/skins/grey.css" rel="stylesheet" type="text/css" />

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  <script src="/templates/pandoc-bootstrap-adaptive-template/script.js"></script>

    <script src="/bower_components/sticky-kit/jquery.sticky-kit.js "></script>
  <meta name="generator" content="pandoc" />
  <title>CSC 665 Fall 2019: Project</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="bootstrap.css" />
</head>
<body>

<!--
    <div class="navbar navbar-static-top">
    <div class="navbar-inner">
      <div class="container">
        <span class="doc-title">CSC 665 Fall 2019: Project</span>
        <ul class="nav pull-right doc-info">
                            </ul>
      </div>
    </div>
  </div>
  -->
  <div class="container">
    <div class="row">
            <div class="span12">
            <nav class="navbar navbar-default">
        <div class="container-fluid">
          <!-- Brand and toggle get grouped for better mobile display -->
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="index.html">CSC 665 S2</a>
          </div>
      
          <!-- Collect the nav links, forms, and other content for toggling -->
          <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav">
              <li><a href="schedule.html">Schedule</a></li>
              <li><a href="syllabus.html">Syllabus</a></li>
              <li><a href="project.html">Project</a></li>
            </ul>
          </div><!-- /.navbar-collapse -->
        </div><!-- /.container-fluid -->
      </nav>
            <h3 id="csc-665-section-2-machine-learning-theory-project">CSC 665 Section 2: Machine Learning Theory: Project</h3>
<h4 id="general-information">General information</h4>
<h4 id="suggested-topics">Suggested topics</h4>
<h5 id="active-learning">Active learning</h5>
<ul>
<li>M.F. Balcan, A. Beygelzimer, J. Langford. Agnostic active learning. ICML 2006.</li>
<li>S. Hanneke. Theory of Disagreement-Based Active Learning. Foundations and Trends in Machine Learning. 2014.</li>
<li>M.F. Balcan and P. Long. Active and Passive Learning of Linear Separators under Log-concave Distributions. COLT 2013.</li>
<li>Chicheng Zhang and Kamalika Chaudhuri. Beyond Disagreement-Based Agnostic Active Learning.</li>
<li>Tzu-Kuo Huang, Alekh Agarwal, Daniel J. Hsu, John Langford, Robert E. Schapire. Efficient and Parsimonious Agnostic Active Learning. NIPS 2015.</li>
<li>Akshay Krishnamurthy, Alekh Agarwal, Tzu-Kuo Huang, Hal Daume III, John Langford. Active Learning for Cost-Sensitive Classification. ICML 2017.</li>
<li>Mina Karzand, Robert D. Nowak. Active Learning in the Overparameterized and Interpolating Regime. 2019.</li>
</ul>
<h5 id="contextual-bandits">Contextual Bandits</h5>
<ul>
<li>John Langford and Tong Zhang The Epoch-Greedy Algorithm for Contextual Multi-armed Bandits. NIPS 2007.</li>
<li>Alekh Agarwal, Miroslav Dudik, Satyen Kale, and John Langford, Contextual Bandit Learning with Predictable Rewards, AISTATS 2012.</li>
<li>Miroslav Dudik, Daniel Hsu, Satyen Kale, Nikos Karampatziakis, John Langford, Lev Reyzin, and Tong Zhang, Efficient Optimal Learning for Contextual Bandits, UAI 2011.</li>
<li>Alekh Agarwal, Daniel Hsu, Satyen Kale, John Langford, Lihong Li, Robert E. Schapire. Taming the Monster: A Fast and Simple Algorithm for Contextual Bandits. ICML 2014.</li>
<li>Dylan J. Foster, Alekh Agarwal, Miroslav Dudík, Haipeng Luo, Robert E. Schapire. Practical Contextual Bandits with Regression Oracles. ICML 2018.</li>
<li>Dylan J. Foster, Akshay Krishnamurthy. Contextual bandits with surrogate losses: Margin bounds and efficient algorithms. NeurIPS 2018.</li>
<li>Akshay Krishnamurthy, John Langford, Aleksandrs Slivkins, Chicheng Zhang. Contextual Bandits with Continuous Actions: Smoothing, Zooming, and Adapting.</li>
</ul>
<h5 id="continuum-armed-bandits">Continuum-armed Bandits</h5>
<ul>
<li>Robert Kleinberg. Nearly Tight Bounds for the Continuum-ArmedBandit Problem. NIPS 2004.</li>
<li>Robert Kleinberg, Aleksandrs Slivkins, Eli Upfal. Multi-Armed Bandits in Metric Spaces. STOC 2008.</li>
<li>Sébastien Bubeck, Rémi Munos, Gilles Stoltz, Csaba Szepesvari. X-armed Bandits. JMLR 2011.</li>
<li>Rémi Munos. From Bandits to Monte-Carlo Tree Search: The Optimistic Principle Applied to Optimization and Planning. Foundations and Trends in Machine Learning. 2014.</li>
<li>Andrea Locatelli, Alexandra Carpentier. Adaptivity to Smoothness in X-armed bandits. COLT 2018.</li>
<li>Hedi Hadiji. Polynomial Cost of Adaptation for X-Armed Bandits. NeurIPS 2019.</li>
</ul>
<h5 id="learning-under-fairness-constraints">Learning under Fairness Constraints</h5>
<ul>
<li>Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold and Richard Zemel. Fairness Through Awareness. ITCS 2012.</li>
<li>Moritz Hardt, Eric Price, Nathan Srebro. Equality of Opportunity in Supervised Learning. NIPS 2016.</li>
<li>Alekh Agarwal, Alina Beygelzimer, Miroslav Dudík, John Langford, Hanna Wallach. A Reductions Approach to Fair Classification. ICML 2018.</li>
<li>Michael Kearns, Seth Neel, Aaron Roth, Zhiwei Steven Wu. Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness. ICML 2018.</li>
</ul>
<h5 id="interactive-imitation-learning">Interactive Imitation Learning</h5>
<p>Hal Daumé III, John Langford, Daniel Marcu. Search-based Structured Prediction. Machine Learning Journal 2009. Stephane Ross, Geoffrey J. Gordon, J. Andrew Bagnell. A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning. AISTATS 2011. Stephane Ross, J. Andrew Bagnell. Reinforcement and Imitation Learning via Interactive No-Regret Learning. NIPS 2014. Wen Sun, Arun Venkatraman, Geoffrey J. Gordon, Byron Boots, J. Andrew Bagnell. Deeply AggreVaTeD: differentiable imitation learning for sequential prediction. ICML 2017. Convergence of Value Aggregation for Imitation Learning. Ching-An Cheng and Byron Boots. NIPS 2017. Wen Sun, Anirudh Vemula, Byron Boots, J. Andrew Bagnell. Provably Efficient Imitation Learning from Observation Alone. ICML 2019.</p>
<h5 id="imitation-learning-and-inverse-reinforcement-learning">Imitation Learning and Inverse Reinforcement Learning</h5>
<p>Pieter Abbeel and AndrewY. Ng. Apprenticeship Learning via Inverse Reinforcement Learning. ICML 2004. Brian D. Ziebart, Andrew Maas, J.Andrew Bagnell, Anind K. Dey. Maximum Entropy Inverse Reinforcement Learning. AAAI 2008. Brian D. Ziebart, J.Andrew Bagnell, Anind K. Dey. Modeling Interaction via the Principle of Maximum Causal Entropy. ICML 2010. Umar Syed and Robert E. Schapire. A Game-Theoretic Approach to ApprenticeshipLearning. NIPS 2007. Jonathan Ho, Stefano Ermon. Generative Adversarial Imitation Learning. NIPS 2016. Kareem Amin, Nan Jiang, Satinder Singh. Repeated Inverse Reinforcement Learning. NIPS 2017.</p>
<h5 id="pac-learning-of-markov-decision-processes">PAC Learning of Markov Decision Processes</h5>
<p>Michael Kearns and Satinder Singh. Near-Optimal Reinforcement Learning in Polynomial Time. Machine Learning, 2002. Ronen I. Brafman and Moshe Tennenholtz. R-max – A General Polynomial Time Algorithm forNear-Optimal Reinforcement Learning. JMLR 2002. Sham Kakade. On the sample complexity of reinforcement learning. University of College London, 2003. Lihong Li, Michael L. Littman, Thomas J. Walsh, Alexander L. Strehl. Knows what it knows: a framework for self-aware learning. Machine Learning, 2011. Nan Jiang. <a href="http://nanjiang.cs.illinois.edu/files/cs598/note7.pdf">Notes on Rmax exploration.</a> Christoph Dann, Tor Lattimore, Emma Brunskill. Unifying PAC and Regret: Uniform PAC Bounds for Episodic Reinforcement Learning. NIPS 2017. Andrea Zanette, Emma Brunskill. Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds. ICML 2019.</p>
            </div>
    </div>
  </div>


  <script src="https://vjs.zencdn.net/5.4.4/video.js"></script>

</body>
</html>
